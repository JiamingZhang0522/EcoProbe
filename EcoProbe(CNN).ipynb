{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = (128, 128)  # Resize images to 128x128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 150\n",
    "LEARNING_RATE = 0.0001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "K_FOLDS = 5  # Number of folds for cross-validation\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"CNN.csv\")\n",
    "\n",
    "# Image transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),  # Convert to tensor and normalize [0,1]\n",
    "])\n",
    "\n",
    "# Custom dataset class\n",
    "class WVREstimationDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.iloc[idx, 0]  # Image filename\n",
    "        img = Image.open(img_name).convert(\"RGB\")  # Open image\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        wvr = torch.tensor(self.dataframe.iloc[idx, 1], dtype=torch.float32)  # WVR value\n",
    "        return img, wvr\n",
    "\n",
    "# Define CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 16 * 16, 128),  # Adjust based on input size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)  # Output single WVR value\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = CNNModel().to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# K-Fold Training Loop\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "    print(f\"Training fold {fold+1}/{K_FOLDS}...\")\n",
    "    \n",
    "    # Create training and validation sets for this fold\n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "    \n",
    "    # Create datasets and dataloaders for this fold\n",
    "    train_dataset = WVREstimationDataset(train_df, transform)\n",
    "    val_dataset = WVREstimationDataset(val_df, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Re-initialize the model for each fold to avoid carrying over weights\n",
    "    model = CNNModel().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # Training loop for this fold\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for images, wvr_values in train_loader:\n",
    "            images, wvr_values = images.to(DEVICE), wvr_values.to(DEVICE).unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, wvr_values)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Fold {fold+1}, Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation after each fold\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, wvr_values in val_loader:\n",
    "            images, wvr_values = images.to(DEVICE), wvr_values.to(DEVICE).unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, wvr_values)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"Fold {fold+1}, Validation Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "# Function to predict WVR for a new image\n",
    "def predict_wvr(image_path, model):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image).item()\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Example usage for final model prediction\n",
    "image_path = \"test_image.png\"  # Replace with actual image path\n",
    "predicted_wvr = predict_wvr(image_path, model)\n",
    "print(f\"Predicted WVR value: {predicted_wvr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = \"image2.png\"  # Replace with actual image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize for CNN input\n",
    "    transforms.ToTensor()  # Convert to tensor (RGB image with 3 channels)\n",
    "])\n",
    "\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Define a simple CNN model with visualization in mind\n",
    "class CNNVisualizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNVisualizer, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 4, kernel_size=3, padding=1)  # 3 channels for RGB input, 4 feature maps\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # Pooling layer\n",
    "\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=3, padding=1)  # 8 feature maps\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # Pooling layer\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(8 * 32 * 32, 1)  # Fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        relu1_out = self.relu1(conv1_out)\n",
    "        pool1_out = self.pool1(relu1_out)\n",
    "\n",
    "        conv2_out = self.conv2(pool1_out)\n",
    "        relu2_out = self.relu2(conv2_out)\n",
    "        pool2_out = self.pool2(relu2_out)\n",
    "\n",
    "        return conv1_out, relu1_out, pool1_out, conv2_out, relu2_out, pool2_out\n",
    "\n",
    "# Initialize model and get outputs\n",
    "model = CNNVisualizer()\n",
    "conv1_out, relu1_out, pool1_out, conv2_out, relu2_out, pool2_out = model(image)\n",
    "\n",
    "# Function to visualize feature maps\n",
    "def visualize_feature_maps(feature_maps, title):\n",
    "    feature_maps = feature_maps.squeeze(0).detach().numpy()  # Remove batch dimension\n",
    "    num_maps = feature_maps.shape[0]\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_maps, figsize=(num_maps * 2, 2))\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "\n",
    "    for i in range(num_maps):\n",
    "        axes[i].imshow(feature_maps[i], cmap=\"jet\")  # Using 'jet' colormap for color scale\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Visualize steps of CNN processing\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(image.squeeze(0).permute(1, 2, 0))  # Convert the tensor back to an image\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "visualize_feature_maps(conv1_out, \"Conv Layer 1 - Feature Maps\")\n",
    "visualize_feature_maps(relu1_out, \"ReLU Activation 1\")\n",
    "visualize_feature_maps(pool1_out, \"Pooling Layer 1\")\n",
    "\n",
    "visualize_feature_maps(conv2_out, \"Conv Layer 2 - Feature Maps\")\n",
    "visualize_feature_maps(relu2_out, \"ReLU Activation 2\")\n",
    "visualize_feature_maps(pool2_out, \"Pooling Layer 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict WVR for a new image\n",
    "def predict_wvr(image_path, model):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image).item()\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "image_path = \"test_image.png\"\n",
    "predicted_wvr = predict_wvr(image_path, model)\n",
    "print(f\"Predicted WVR value: {predicted_wvr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
